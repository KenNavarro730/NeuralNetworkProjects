{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TransformerArchitectureFromScratch.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Note: If you're a recruiter for a company I applied for, I am willing to explain each part of this process as well as re implement the entire thing from scratch infront of you."
      ],
      "metadata": {
        "id": "kNdRU89DWQem"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "import tensorflow_datasets as tfds \n",
        "import tensorflow_text as text \n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "-QfeyUKHWzQx"
      },
      "execution_count": 283,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def angles(pos, i, d_model):\n",
        "  angle_rates = i/np.power(10000, (2*(i//2))/np.float32(d_model))\n",
        "  return pos * angle_rates\n",
        "def positional_encoding(pos, d_model):\n",
        "  angless = angles(np.arange(pos)[:, np.newaxis], np.arange(d_model)[np.newaxis, :], d_model) #The np.newaxis makes the positional vector based off rows and d_model based off col\n",
        "  angless[:, 0::2] = np.sin(angless[:, 0::2])\n",
        "  angless[:, 1::2] = np.cos(angless[:, 1::2])\n",
        "  pos_encoding = angless[np.newaxis, ...] #The ... simply means add the rest of what was already in there \n",
        "  return tf.cast(pos_encoding, tf.float32) #Makes the numpy array a tensor of float 32 values"
      ],
      "metadata": {
        "id": "5KPnGZDpZDpW"
      },
      "execution_count": 253,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_padding_mask(seq):\n",
        "  seqq = tf.cast(tf.math.equal(seq, 0),tf.float32) #Sets the values in the .equal to a tensor of type float 32 \n",
        "  return seqq[:, tf.newaxis, tf.newaxis, :] #batch_size,1,1,seq_len This mask is for encoder and beginning decoder layer"
      ],
      "metadata": {
        "id": "DzezecfNcCSe"
      },
      "execution_count": 254,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_look_ahead_mask(size):\n",
        "  vals = 1 - tf.linalg.band_part(tf.ones((size,size)),-1, 0)\n",
        "  return vals "
      ],
      "metadata": {
        "id": "j6xibMo_cy6a"
      },
      "execution_count": 255,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scaled_dot_product_attention(q, k, v, mask):\n",
        "  dotproductssf = tf.matmul(q, k, transpose_b=True)\n",
        "  dotproductssf = dotproductssf/tf.math.sqrt(tf.cast(tf.shape(k)[-1], tf.float32))\n",
        "  #dont forget before we can softmax we gotta add the mask as this is what will zero out the values when we do softmax!\n",
        "  #Notice the reason we added the two neq dimensions was so we could implement it in this way \n",
        "  if mask is not None:\n",
        "    dotproductssf += (mask*-1e9) #(note that only the mask with a 1 will affect input, the ones with a 0 dont affect input since we are effectively adding and not multiplying!)\n",
        "  dotproductssf = tf.nn.softmax(dotproductssf, axis=-1)\n",
        "  output = tf.matmul(dotproductssf, v, transpose_b=True)\n",
        "  return output, dotproductssf #dotproductssf represents the attention weights, i feel like the reason we may have to keep track of this is so when we pass it to a dense layer \n",
        "  #It knows the kind of weights to initialize our stuff with"
      ],
      "metadata": {
        "id": "83qxXRJqdKvA"
      },
      "execution_count": 256,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "  #this inheritance lets us basically become a layer \n",
        "  def __init__(self, d_model, num_heads):\n",
        "    super(MultiHeadAttention, self).__init__()\n",
        "    self.num_heads = num_heads \n",
        "    self.d_model = d_model \n",
        "    assert self.d_model % self.num_heads == 0 #else we will have a remainder in split and that would be awkward lmaooo \n",
        "    self.depth = self.d_model // self.num_heads #This returns the floor value, so rounding down in case its a float \n",
        "    #In order to actually get the weight matrices we are going to use a dense layer the size of d_model this will make sure the multihead attention attends weight to each of the split\n",
        "    self.wq = tf.keras.layers.Dense(d_model)\n",
        "    self.wk = tf.keras.layers.Dense(d_model)\n",
        "    self.wv = tf.keras.layers.Dense(d_model)\n",
        "    #Remember that after the attention output our matrices are going to be a weird size after we do all the split multiplications, so we ues another dense layer with a fixed unit\n",
        "    #size, that we want to output the entire model as! \n",
        "    self.dense = tf.keras.layers.Dense(d_model) \n",
        "  def split_heads(self, x, batch_size):\n",
        "    #To split into num_heads and depth, we need to use the d_model \n",
        "    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth)) #batch size, seq len, num heads, depth\n",
        "    return tf.transpose(x, perm = [0, 2, 1, 3]) #However now we move it to batch size, num heads, seq len, depth because this is the way I suppose tensorflow likes its transposed \n",
        "  def call(self, v, k, q, mask):\n",
        "    batch_size = tf.shape(q)[0] #Since tensors like to have batch size in first index and q.batch_size = k.batch_size = v.batch_size which implies we can pick any q,k,v\n",
        "    q = self.wq(q)\n",
        "    k = self.wk(k)\n",
        "    v = self.wv(v)\n",
        "    q = self.split_heads(q, batch_size)\n",
        "    k = self.split_heads(k, batch_size)\n",
        "    v = self.split_heads(v, batch_size)\n",
        "    scaled_attention, attention_weights = scaled_dot_product_attention(q, k, v, mask)\n",
        "    scaled_attention = tf.transpose(scaled_attention, perm = [0, 2,1,3]) #moves it back to batch_size, seq_len, num_heads, depth in order to reshape\n",
        "    concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n",
        "    output = self.dense(concat_attention) #Makes it go back to original size type of attention size if not alrdy!\n",
        "    return output, attention_weights #:D Attention weights in my best guess will probably be used for the feedforward layers in order to have starting values \n",
        "\n"
      ],
      "metadata": {
        "id": "QjhIdVjpdqiN"
      },
      "execution_count": 257,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def point_wise_feed_forward_network(d_model, dff):\n",
        "  return tf.keras.Sequential([\n",
        "                tf.keras.layers.Dense(dff, activation = 'relu'),\n",
        "                tf.keras.layers.Dense(d_model)\n",
        "  ])\n"
      ],
      "metadata": {
        "id": "WvwY5PtAjOoa"
      },
      "execution_count": 258,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, dff, rate = 0.1):\n",
        "    super(EncoderLayer, self).__init__()\n",
        "    #in an encoder layer, we embed vals, consider in positional encoding, \n",
        "    self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon = 1e-6)\n",
        "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon = 1e-6)\n",
        "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "  def call(self, x, training, mask): #Note: 'training' is simply dictating whether we want to train this specific layer or not when building or rather inferencing w/our transformer\n",
        "    attn_output, _ = self.mha(x,x,x, mask)\n",
        "    attn_output = self.dropout1(attn_output, training = training)\n",
        "    out1 = self.layernorm1(attn_output + x) \n",
        "    ffn_output = self.ffn(out1)\n",
        "    ffn_output = self.dropout2(ffn_output, training = training)\n",
        "    out2 = self.layernorm2(ffn_output + out1)\n",
        "\n",
        "    return out2 "
      ],
      "metadata": {
        "id": "exbF69KhjfzZ"
      },
      "execution_count": 259,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "    super(DecoderLayer, self).__init__() \n",
        "    self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
        "    self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
        "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout3 = tf.keras.layers.Dropout(rate)\n",
        "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "  def call(self, x, enc_output, training, look_ahead_mask, padding_mask): #We associate a training with each one of these layers for the same reason of giving us the option of whether to freeze or not \n",
        "    selfatt, attweight1 = self.mha1(x,x,x,look_ahead_mask)\n",
        "    selfatt = self.dropout1(selfatt, training = training)\n",
        "    out1 = self.layernorm1(selfatt + x)\n",
        "    output2, attweight2 = self.mha2(enc_output,enc_output, out1, padding_mask)\n",
        "    output2 = self.dropout2(output2, training = training)\n",
        "    out2 = self.layernorm2(output2 + out1)\n",
        "    output3 = self.ffn(out2)\n",
        "    output3 = self.dropout3(output3, training = training)\n",
        "    out3 = self.layernorm3(output3 + out2)\n",
        "    return out3, attweight1, attweight2"
      ],
      "metadata": {
        "id": "NaYiUKG_mIso"
      },
      "execution_count": 260,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_layers, d_model,num_heads, dff, input_vocab_size, maximum_positional_encoding,rate=0.1):\n",
        "    super(Encoder, self).__init__()\n",
        "    #How I think its gonna go, we are going to first start off by creating our padding mask from the tokens, then we are going to implementing embedding.\n",
        "    #After we implement the embedding we are then going to deploy the encoder layer on it for number of times we have num layer.\n",
        "    self.d_model = d_model \n",
        "    self.num_layers = num_layers\n",
        "    self.pos_encoding = positional_encoding(maximum_positional_encoding, self.d_model)\n",
        "    self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
        "    self.enc = [EncoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n",
        "    self.dropout = tf.keras.layers.Dropout(rate)\n",
        "  def call(self, x, training, padding_mask): #Note that since positional encoding doesnt rely at all on the actual values inside of the embeddings, we are alrdy good there \n",
        "    seq_len = tf.shape(x)[1]\n",
        "    x = self.embedding(x)\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    x += self.pos_encoding[:, :seq_len, :]\n",
        "    x = self.dropout(x, training = training)\n",
        "    for i in range(self.num_layers):\n",
        "      x = self.enc[i](x, training, padding_mask)\n",
        "    return x"
      ],
      "metadata": {
        "id": "cvua2WcToeJv"
      },
      "execution_count": 261,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_layers, d_model, num_heads,dff, target_vocab_size,maximum_positional_encoding,rate=0.1):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.num_layers = num_layers \n",
        "    self.d_model = d_model \n",
        "    self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
        "    self.pos_encoding = positional_encoding(maximum_positional_encoding, d_model)\n",
        "    self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n",
        "    self.dropout = tf.keras.layers.Dropout(rate)\n",
        "  def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
        "    seq_len = tf.shape(x)[1] #This is making sure columns match when we do pos encoding \n",
        "    x = self.embedding(x)\n",
        "    attention_weights = {}\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32)) #I guess we multiply by sqrt of d_model to normalize?\n",
        "    x += self.pos_encoding[:, :seq_len, :]\n",
        "    x = self.dropout(x, training=training)\n",
        "    for i in range(self.num_layers):\n",
        "      x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask) \n",
        "      attention_weights[f'decoder_layer{i+1}_block1'] = block1 \n",
        "      attention_weights[f'decoder_layer{i+1}_block2'] = block2 #This gives a key value pair keeping track of weights so we can easily index! \n",
        "    return x, attention_weights"
      ],
      "metadata": {
        "id": "imE9XPQ8shPO"
      },
      "execution_count": 262,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(tf.keras.Model):\n",
        "  def __init__(self,num_layers, d_model, num_heads, dff, input_vocab_size, target_vocab_size, pe_input, pe_target, rate=0.1):\n",
        "    super().__init__()\n",
        "    self.encoder = Encoder(num_layers, d_model, num_heads, dff, input_vocab_size, pe_input, rate)\n",
        "    self.decoder = Decoder(num_layers, d_model,num_heads, dff, target_vocab_size, pe_target, rate)\n",
        "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "  def call(self, inputs, training):\n",
        "    #Keras models prefer all inputs into first argument \n",
        "    inp, tar = inputs \n",
        "    enc_padding_mask, look_ahead_mask, dec_padding_mask  = self.create_masks(inp, tar)\n",
        "    enc_output = self.encoder(inp, training,enc_padding_mask)\n",
        "    dec_output, attention_weights = self.decoder(tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
        "    final_output = self.final_layer(dec_output)\n",
        "    return final_output, attention_weights \n",
        "  def create_masks(self, inp, tar):\n",
        "    #Encoder padding mask\n",
        "    enc_padding_mask = create_padding_mask(inp)\n",
        "    dec_padding_mask = create_padding_mask(tar)\n",
        "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
        "    dec_target_padding_mask = create_padding_mask(tar)\n",
        "    look_ahead_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
        "\n",
        "    return enc_padding_mask, look_ahead_mask, dec_padding_mask "
      ],
      "metadata": {
        "id": "JX5oOgsdwoNM"
      },
      "execution_count": 263,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Now we are done with that :), we simply have to setup hyperparameters"
      ],
      "metadata": {
        "id": "UtTm5uxf0o0r"
      },
      "execution_count": 264,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_layers = 4\n",
        "d_model = 128\n",
        "dff = 512\n",
        "num_heads = 8\n",
        "dropout_rate = 0.1"
      ],
      "metadata": {
        "id": "kqq1g1JG1AZi"
      },
      "execution_count": 265,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "  def __init__(self, d_model, warmup_steps = 4000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "    self.d_model = d_model \n",
        "    self.d_model = tf.cast(self.d_model, tf.float32) #This learning rate is strictly based off of the dimensionality of the model\n",
        "    self.warmup_steps = warmup_steps \n",
        "  def __call__(self, step):\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps ** -1.5)\n",
        "    return tf.math.rsqrt(self.d_model)*tf.math.minimum(arg1, arg2)"
      ],
      "metadata": {
        "id": "sBIDkhEp1GKE"
      },
      "execution_count": 266,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = CustomSchedule(d_model)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)"
      ],
      "metadata": {
        "id": "3zbnX1ui1mAO"
      },
      "execution_count": 267,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True, reduction = 'none')"
      ],
      "metadata": {
        "id": "Av-d9C-d11YS"
      },
      "execution_count": 268,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "  mask = tf.cast(mask, dtype = loss_.dtype)\n",
        "  loss_ *= mask\n",
        "  return tf.reduce_sum(loss_)/tf.reduce_sum(mask) #reduce sum flattens and then sums"
      ],
      "metadata": {
        "id": "l-OAl4AD2CXu"
      },
      "execution_count": 269,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy_function(real, pred):\n",
        "  accuracies = tf.equal(real, tf.argmax(pred, axis=2))\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  accuracies = tf.math.logical_and(mask, accuracies)\n",
        "  accuracies = tf.cast(accuracies, dtype = tf.float32)\n",
        "  mask = tf.cast(mask, dtype=tf.float32)\n",
        "  return tf.reduce_sum(accuracies)/tf.reduce_sum(mask)\n"
      ],
      "metadata": {
        "id": "X_TW1PdF2dCN"
      },
      "execution_count": 270,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.Mean(name='train_accuracy')"
      ],
      "metadata": {
        "id": "ffUJldbJ2yFX"
      },
      "execution_count": 271,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer = Transformer(num_layers = num_layers, d_model = d_model, num_heads = num_heads, dff = dff, input_vocab_size=tokenizer.pt.get_vocab_size().numpy(),\n",
        "                          target_vocab_size = tokenizer.en.get_vocab_size().numpy(), pe_input=1000, pe_target=1000, rate = dropout_rate)"
      ],
      "metadata": {
        "id": "24Bb8e3723n5"
      },
      "execution_count": 272,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer.compile(optimizer = optimizer, loss = tf.keras.losses.SparseCategoricalCrossentropy, metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "gtrFWSvvSjvg"
      },
      "execution_count": 279,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sXGPDVp3JwY",
        "outputId": "4597285b-a2f4-4a19-f2b7-ff69fb75c84d"
      },
      "execution_count": 281,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"transformer_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " encoder_13 (Encoder)        multiple                  1787008   \n",
            "                                                                 \n",
            " decoder_6 (Decoder)         multiple                  1955584   \n",
            "                                                                 \n",
            " dense_471 (Dense)           multiple                  904290    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,646,882\n",
            "Trainable params: 4,646,882\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This was probably the most intense build from scratch project i've done. Pretty exhausting but this taught me a lot about implementation in code, it also taught me a lot about tensorflow rules. It's nice because with this I feel a lot more confident in my ability to build great deep learning architectures. This crap took me so many hours to understand before I could even start building lol."
      ],
      "metadata": {
        "id": "qty37U6mTbn3"
      }
    }
  ]
}